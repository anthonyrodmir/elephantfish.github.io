{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flava\n",
    "\n",
    "* [github](https://github.com/facebookresearch/multimodal/tree/main/examples/flava)\n",
    "* [paper](https://arxiv.org/abs/2112.04482)\n",
    "* [HF flava-full](https://huggingface.co/facebook/flava-full)\n",
    "* [HF FLAVA overview](https://huggingface.co/docs/transformers/v4.35.2/en/model_doc/flava)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, FlavaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b864ef996c0417cb7e9adbeab8ce828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/8.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `FlavaTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`multimodal_config_dict` is provided which will be used to initialize `FlavaMultimodalConfig`. The value `multimodal_config[\"id2label\"]` will be overriden.\n",
      "`image_codebook_config_dict` is provided which will be used to initialize `FlavaImageCodebookConfig`. The value `image_codebook_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fe8c0735dc445db7b01abbaa925c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2ce8d5a7014059a6cd5b21a26cd0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee95c9640904eb0b2e492f20c2205fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c3238e29e94af99a844f39e11fcd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/358 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = FlavaModel.from_pretrained('facebook/flava-full')\n",
    "tokenizer = BertTokenizer.from_pretrained('facebook/flava-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/modeling_utils.py:900: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs={'input_ids': tensor([[ 101, 1037, 6302, 1997, 1037, 3899,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "text_embedding=tensor([[[-0.0185, -0.0586,  0.0698,  ..., -0.0318, -0.1119,  0.0276],\n",
      "         [-0.0281, -0.0103, -0.0487,  ...,  0.0140,  0.0151, -0.0027],\n",
      "         [ 0.0016, -0.0051, -0.0045,  ..., -0.0174,  0.0044, -0.0500],\n",
      "         ...,\n",
      "         [-0.0257, -0.0431,  0.0912,  ..., -0.0370, -0.0974,  0.0564],\n",
      "         [-0.0431, -0.1407, -0.0212,  ..., -0.0893,  0.0681,  0.0106],\n",
      "         [-0.0094, -0.0838, -0.0464,  ..., -0.0334,  0.0361,  0.0641]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "text = 'a photo of a dog'\n",
    "\n",
    "inputs = tokenizer(text=[text], return_tensors='pt', padding='max_length', max_length=77)\n",
    "text_embedding = model.get_text_features(**inputs)\n",
    "\n",
    "print(f'{inputs=}')\n",
    "print(f'{text_embedding=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/modeling_utils.py:900: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FlavaModelOutput(image_embeddings=None, image_output=None, text_embeddings=tensor([[[-0.0368, -0.0724,  0.0760,  ...,  0.0791, -0.0479, -0.0352],\n",
       "         [ 0.0868,  0.1197, -0.0628,  ...,  0.0034, -0.1115, -0.0629],\n",
       "         [ 0.1619, -0.0906, -0.1539,  ..., -0.0072, -0.0943, -0.0101],\n",
       "         ...,\n",
       "         [ 0.0184, -0.1864, -0.0139,  ...,  0.1110, -0.1123,  0.1378],\n",
       "         [ 0.0919, -0.1461, -0.0332,  ...,  0.0883, -0.1369,  0.1401],\n",
       "         [ 0.0362, -0.1163, -0.0421,  ...,  0.0930, -0.1191,  0.1248]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), text_output=BaseModelOutputWithPooling(last_hidden_state=tensor([[[-0.0368, -0.0724,  0.0760,  ...,  0.0791, -0.0479, -0.0352],\n",
       "         [ 0.0868,  0.1197, -0.0628,  ...,  0.0034, -0.1115, -0.0629],\n",
       "         [ 0.1619, -0.0906, -0.1539,  ..., -0.0072, -0.0943, -0.0101],\n",
       "         ...,\n",
       "         [ 0.0184, -0.1864, -0.0139,  ...,  0.1110, -0.1123,  0.1378],\n",
       "         [ 0.0919, -0.1461, -0.0332,  ...,  0.0883, -0.1369,  0.1401],\n",
       "         [ 0.0362, -0.1163, -0.0421,  ...,  0.0930, -0.1191,  0.1248]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 1.3338e-09, -1.8539e-07,  2.5638e-07, -1.3631e-07,  7.3593e-08,\n",
       "         -5.5894e-08, -5.9832e-08, -5.0753e-08,  1.5598e-07, -1.6937e-07,\n",
       "         -3.5682e-08,  7.5560e-08,  9.8822e-08, -4.2336e-08, -2.4418e-07,\n",
       "         -1.7201e-08, -3.8401e-08,  1.6519e-07,  1.2852e-08, -1.2614e-07,\n",
       "         -2.4024e-09,  1.8536e-07,  2.8704e-08, -1.0849e-07,  5.8747e-09,\n",
       "         -4.9226e-08, -6.3682e-08, -1.8839e-07,  5.9785e-08,  4.4448e-08,\n",
       "         -2.0263e-08,  9.0726e-09,  7.8493e-08, -5.7834e-08, -1.5499e-08,\n",
       "          3.8471e-08, -1.6245e-08,  1.9890e-07, -8.3798e-08,  1.6752e-07,\n",
       "          2.9678e-08,  1.0350e-08,  1.3173e-07,  4.7409e-08,  4.6931e-08,\n",
       "          5.4433e-08,  1.4076e-07, -1.7993e-07, -1.1863e-07,  2.6220e-07,\n",
       "         -6.5447e-08,  5.8304e-08, -1.1442e-08, -3.6357e-08, -3.2605e-08,\n",
       "          1.2046e-07,  1.0055e-07, -8.7200e-08,  1.4747e-07, -9.8159e-09,\n",
       "         -1.1256e-07,  1.1258e-07,  1.0727e-07, -1.9703e-08, -1.5225e-07,\n",
       "          1.7310e-07,  4.9343e-08, -3.4057e-08,  6.2867e-08, -7.3013e-08,\n",
       "          1.1441e-07,  2.1350e-07,  6.1319e-08, -7.3731e-09, -7.4461e-08,\n",
       "          4.0604e-09,  1.2298e-07,  1.7296e-07,  1.7594e-07,  7.0785e-08,\n",
       "          1.8277e-07,  2.4854e-07, -7.8753e-08,  9.2809e-10,  3.6206e-08,\n",
       "          1.0492e-07, -1.4593e-07, -7.2950e-08,  2.8029e-07, -8.2998e-08,\n",
       "          1.9874e-08, -6.8915e-09, -5.1467e-08, -2.9259e-07,  1.2533e-07,\n",
       "          7.7874e-08,  1.2150e-07,  9.1007e-08, -8.0276e-09, -1.1759e-07,\n",
       "          8.3238e-08, -4.1410e-09,  1.7380e-07, -3.5408e-08,  3.3537e-10,\n",
       "         -3.0909e-09,  9.1957e-09, -1.7543e-07, -1.8316e-07,  2.5515e-08,\n",
       "          1.2129e-07,  7.7602e-08,  1.6542e-07,  1.5264e-07,  1.0725e-07,\n",
       "          3.0156e-07,  1.8763e-07,  1.1630e-07,  1.5189e-07, -9.1854e-08,\n",
       "         -2.6435e-08,  3.7029e-08, -1.7649e-08,  7.8018e-08,  2.7638e-08,\n",
       "         -4.0129e-09, -7.3577e-08,  5.6892e-08, -2.8278e-08,  7.9923e-08,\n",
       "          6.4949e-08, -7.6141e-08, -2.0185e-07, -3.2300e-09,  3.2810e-09,\n",
       "         -1.6896e-07, -1.0922e-08, -4.3713e-08, -4.8392e-08, -1.2235e-07,\n",
       "          4.4002e-08,  6.4111e-08, -2.5493e-08,  1.1828e-07,  1.2614e-07,\n",
       "         -1.3770e-07,  3.3043e-08, -1.6341e-07, -2.4500e-07,  5.0103e-08,\n",
       "          1.1038e-07, -2.8938e-08, -8.8058e-08,  8.5418e-08,  1.6574e-07,\n",
       "          7.9525e-08,  1.1118e-07, -5.6480e-08,  3.0431e-08,  6.7663e-08,\n",
       "          2.0428e-07,  1.1997e-07, -2.2167e-07, -1.4182e-07,  1.7383e-07,\n",
       "         -1.6275e-08, -1.7828e-07,  2.1577e-08, -5.8348e-08, -2.1000e-07,\n",
       "         -1.6211e-07,  1.8147e-07,  1.6543e-07, -3.3628e-08, -8.1757e-08,\n",
       "         -1.2993e-07, -2.9858e-08,  4.1445e-08,  5.4524e-08, -1.3858e-07,\n",
       "         -1.9942e-08, -5.7489e-08,  1.8155e-07,  5.6637e-08,  1.1066e-07,\n",
       "          1.1800e-07, -6.2174e-08, -3.3208e-08,  1.8570e-07, -2.2910e-08,\n",
       "         -6.8735e-08, -1.1621e-07, -1.3512e-07,  6.8415e-10,  1.2287e-07,\n",
       "         -6.5202e-08, -4.2220e-09, -1.1265e-07,  1.2448e-08,  8.8669e-08,\n",
       "         -5.8172e-08,  5.0133e-08,  9.0896e-08, -1.4793e-07,  8.4381e-08,\n",
       "         -1.0987e-07, -7.2986e-08,  1.4540e-07,  4.6245e-08, -1.3307e-07,\n",
       "          1.7361e-07, -2.4784e-07,  7.0419e-08,  2.6531e-07,  3.2768e-08,\n",
       "          1.1611e-08, -5.7709e-08,  2.5671e-07, -1.5520e-09,  2.0680e-07,\n",
       "         -4.9485e-08, -2.1542e-08, -5.5414e-09,  7.1880e-09,  7.2571e-08,\n",
       "          9.5126e-08,  1.9022e-08,  1.7281e-07, -2.4044e-08,  1.5413e-07,\n",
       "          4.8973e-08, -3.1016e-08,  2.8773e-08,  1.7632e-07,  7.5134e-08,\n",
       "         -2.6024e-08, -5.3191e-09,  7.9598e-08, -1.4696e-07,  7.2790e-09,\n",
       "         -1.2703e-08, -6.7202e-08, -2.4200e-07,  6.7884e-08,  3.7662e-08,\n",
       "          4.5966e-08,  1.4143e-07,  1.1052e-07,  1.4001e-07,  1.9770e-07,\n",
       "         -5.2296e-08, -9.0919e-08,  6.6382e-08,  5.6054e-08, -3.4671e-08,\n",
       "         -9.9177e-08,  4.8087e-08, -5.3511e-08, -2.0275e-08, -2.0661e-08,\n",
       "         -1.9146e-07,  2.8246e-08, -2.3230e-07, -1.2986e-07,  2.6935e-07,\n",
       "          7.1943e-08,  1.1877e-07, -1.1826e-07,  4.1712e-08,  6.4183e-08,\n",
       "          8.7179e-09, -4.0726e-08, -1.6752e-08, -1.3739e-07,  1.9534e-07,\n",
       "          9.6560e-08,  2.8382e-08,  1.5885e-07, -1.9050e-07, -2.4893e-07,\n",
       "          7.3151e-08,  1.4695e-07,  2.1434e-07,  7.9055e-11,  2.0664e-08,\n",
       "          1.1094e-07, -9.3260e-08,  3.6405e-09,  9.5241e-08,  1.4326e-07,\n",
       "          7.2546e-08, -3.4851e-08, -5.0079e-08, -6.1045e-09,  4.0151e-08,\n",
       "          7.5470e-08, -3.9776e-09, -1.9431e-07, -4.6976e-08,  2.5643e-08,\n",
       "          6.2191e-08,  1.1685e-07,  1.3187e-08,  2.1211e-07,  5.5230e-09,\n",
       "          8.6890e-08,  3.0518e-08, -9.2435e-10,  1.8179e-07, -8.7254e-08,\n",
       "         -1.1499e-08, -1.9940e-07, -3.3127e-09,  8.8339e-08,  1.3889e-07,\n",
       "          2.3532e-07, -1.5284e-07, -1.8313e-07,  4.9279e-08,  9.8439e-08,\n",
       "         -1.7798e-07, -3.6779e-08,  1.6277e-08, -2.7810e-07, -1.1581e-07,\n",
       "          4.8627e-09,  5.4032e-08, -5.5260e-08,  6.2372e-08, -2.0430e-07,\n",
       "          9.1620e-08,  8.0799e-08, -8.3596e-08, -3.9088e-08, -1.4369e-07,\n",
       "          3.1823e-08, -1.0524e-07, -3.4173e-08,  3.5583e-08, -5.6949e-08,\n",
       "          8.8268e-08, -1.8677e-09,  3.7679e-09,  3.2921e-08,  2.4394e-07,\n",
       "          1.4206e-07,  3.3562e-08,  9.3199e-08,  9.1285e-08,  4.8772e-08,\n",
       "         -1.1078e-07,  9.7152e-08, -1.5600e-08,  3.4344e-08,  4.3439e-08,\n",
       "         -1.4668e-08,  3.1980e-08, -5.1306e-08, -2.0784e-07,  9.9056e-08,\n",
       "         -2.1100e-07,  2.5281e-08, -1.7257e-08, -1.6389e-07, -1.2909e-08,\n",
       "          3.5877e-08,  4.3146e-08, -6.7762e-08,  1.8895e-07, -1.3875e-08,\n",
       "         -8.1653e-08,  9.6333e-08,  5.4419e-08, -2.4358e-07, -4.4201e-08,\n",
       "         -6.1288e-08,  5.9829e-08,  2.3680e-07,  1.8155e-07, -6.8823e-09,\n",
       "         -3.5585e-08,  1.3384e-07, -1.7808e-08, -5.5697e-08, -3.9406e-08,\n",
       "         -4.3661e-08,  5.3328e-08,  1.9749e-08, -1.3963e-07, -8.4492e-08,\n",
       "          5.5709e-08,  2.6329e-08,  1.5950e-07, -7.2837e-08, -1.6937e-07,\n",
       "          3.7139e-08, -6.5711e-08, -9.7359e-09,  4.4699e-08, -2.2021e-07,\n",
       "          3.4408e-08, -3.3861e-08, -1.6170e-08,  1.6444e-07,  2.7344e-07,\n",
       "          5.3122e-08, -2.0926e-07,  3.2580e-08, -3.9929e-08, -1.6868e-07,\n",
       "          2.6514e-08, -4.5423e-09, -1.4179e-07, -7.6378e-08, -6.8524e-08,\n",
       "          2.1930e-07, -1.7305e-08,  1.1209e-07, -2.7936e-09, -7.3669e-08,\n",
       "          4.5340e-08, -7.4028e-08,  2.3459e-07,  1.2622e-07,  4.4721e-08,\n",
       "          1.3655e-07, -1.1760e-08,  9.5381e-08, -2.0988e-08, -2.4427e-08,\n",
       "         -2.5579e-07, -2.5679e-07, -8.6121e-09, -9.6144e-08, -1.5011e-08,\n",
       "          4.6320e-08,  5.1767e-08,  8.5199e-08, -1.8753e-07, -1.2912e-07,\n",
       "         -1.3956e-07,  1.5010e-07, -5.4272e-08, -7.0576e-08,  1.1561e-07,\n",
       "         -1.2257e-07, -7.7755e-08, -7.3268e-08, -3.8566e-08, -4.4666e-08,\n",
       "          2.7074e-08, -8.5601e-08, -2.9833e-08,  9.7175e-08, -1.3514e-07,\n",
       "         -1.0190e-07,  1.9340e-08,  1.7146e-08,  1.0881e-07,  1.2360e-07,\n",
       "          2.3843e-07,  1.6318e-07,  1.2019e-07, -1.7045e-07, -1.9997e-07,\n",
       "         -1.2129e-07,  1.2439e-08,  5.1194e-08,  1.0992e-07, -2.3568e-07,\n",
       "          1.5391e-08,  3.3447e-08,  7.8406e-08, -4.3904e-08, -1.2069e-07,\n",
       "         -4.0266e-08, -2.8464e-08,  3.9569e-08, -1.6838e-08, -4.2667e-08,\n",
       "         -6.3813e-08,  8.8201e-08, -1.0085e-07,  2.2530e-07,  1.7349e-07,\n",
       "          1.1620e-09, -5.8668e-08, -1.0382e-08,  1.5017e-07, -8.6486e-08,\n",
       "          1.4344e-07,  2.9121e-08,  1.0521e-07,  8.3142e-08, -3.9456e-08,\n",
       "         -1.0593e-08,  9.5146e-08,  3.8135e-07,  4.0886e-08,  2.1029e-07,\n",
       "          2.2074e-07, -5.1222e-08,  4.8350e-08, -4.8413e-08,  1.2253e-07,\n",
       "          1.3007e-07,  1.2224e-07,  1.4370e-08,  5.3773e-08,  4.2577e-08,\n",
       "         -6.7909e-08, -8.4863e-08,  2.9483e-08,  1.2488e-07,  1.4211e-08,\n",
       "          6.9542e-09,  7.3591e-08,  2.3519e-08, -3.9224e-08,  4.9733e-08,\n",
       "         -3.3917e-09, -1.6241e-07, -4.1592e-08,  3.5723e-08,  1.6773e-07,\n",
       "          7.7683e-08, -1.5475e-07, -6.0676e-08,  5.5456e-08,  1.1532e-07,\n",
       "         -1.9750e-07,  2.3257e-07, -5.6397e-08, -4.0235e-09, -3.4312e-08,\n",
       "          2.3871e-07, -6.4382e-08, -8.5121e-08, -1.0755e-07, -4.6999e-08,\n",
       "          6.2511e-08, -1.1531e-07, -2.3211e-08, -5.5813e-08,  1.3726e-07,\n",
       "          1.7769e-08, -1.7271e-07, -2.3919e-08, -4.7271e-08,  9.6087e-09,\n",
       "          6.4370e-08, -8.5587e-08,  3.1425e-08, -2.3099e-08,  7.6170e-08,\n",
       "         -1.1739e-07, -1.5088e-07,  4.4884e-08,  2.2237e-07,  4.1657e-08,\n",
       "         -3.2050e-07,  2.4461e-07,  1.0917e-07,  2.3604e-07,  9.6733e-08,\n",
       "          1.7770e-07, -6.6462e-08,  5.9085e-08,  7.5497e-09, -1.9289e-07,\n",
       "          4.7761e-08,  1.0604e-07,  6.9648e-08,  2.2516e-09,  2.0255e-08,\n",
       "          7.2312e-08,  3.0342e-07, -1.6119e-07,  9.0987e-08, -2.4198e-07,\n",
       "          1.0441e-07, -1.5417e-07,  2.3535e-07,  2.3990e-08,  1.5677e-07,\n",
       "          6.1552e-10,  1.6934e-08, -2.1446e-08,  5.6936e-08, -2.7099e-07,\n",
       "         -1.6537e-07,  9.2651e-08,  7.6670e-09, -5.9509e-08,  9.3600e-09,\n",
       "          6.6907e-08, -2.8742e-08,  9.4062e-08,  2.5052e-08, -5.7860e-09,\n",
       "          2.1243e-08, -1.5215e-07, -9.2049e-09, -5.7255e-08,  2.1362e-07,\n",
       "         -1.3679e-08, -2.4908e-08, -8.1550e-08,  2.5685e-07, -1.2028e-07,\n",
       "         -9.2070e-08, -1.5330e-07, -1.4230e-07, -5.3347e-08,  5.4448e-09,\n",
       "          8.6232e-09,  6.3396e-08,  5.0834e-08,  3.2770e-09,  1.7521e-08,\n",
       "          3.5998e-08, -2.0040e-07,  1.7524e-07, -2.0844e-08, -9.5226e-08,\n",
       "         -1.2535e-07,  1.9375e-07,  6.3380e-08, -9.9826e-09,  8.2644e-08,\n",
       "         -4.7509e-08,  5.0292e-08,  1.0103e-07, -5.5222e-08,  3.0027e-09,\n",
       "          6.6470e-08, -1.7218e-07, -7.8994e-08, -1.2317e-09,  6.0165e-08,\n",
       "          1.2151e-07,  6.3811e-08, -6.9937e-08, -7.2033e-08, -5.0594e-08,\n",
       "         -1.1766e-08, -7.6657e-08,  2.5839e-07, -1.7599e-08,  2.7094e-08,\n",
       "         -8.0708e-08,  9.0291e-08, -2.7069e-08, -1.6178e-07,  1.4394e-07,\n",
       "         -1.3637e-07, -1.1177e-07,  9.3325e-08, -1.3210e-08,  1.1536e-07,\n",
       "         -9.0911e-08, -2.1387e-07, -8.1694e-08,  1.3646e-07,  1.1346e-07,\n",
       "          6.6197e-08,  1.3484e-08,  7.7376e-08, -2.8790e-08, -4.0388e-08,\n",
       "         -7.4255e-08, -1.5137e-07,  1.0676e-07,  2.0093e-07, -6.9876e-08,\n",
       "         -7.0464e-08, -7.9707e-08,  1.3986e-08,  1.3434e-07,  3.1174e-08,\n",
       "          9.4598e-08, -2.8416e-08, -1.0490e-08,  2.7067e-09, -1.2366e-07,\n",
       "         -1.1229e-07, -5.8714e-08,  6.9627e-08,  4.6743e-09,  2.0807e-07,\n",
       "         -3.8319e-08, -3.7447e-07,  1.6738e-07, -6.3046e-08,  4.0268e-08,\n",
       "         -5.9453e-08,  2.1332e-07,  9.7647e-08,  1.9122e-07,  9.2312e-08,\n",
       "          4.9751e-08,  9.5904e-08, -2.0444e-08,  6.5314e-08, -2.7117e-08,\n",
       "          2.5207e-07, -1.2916e-08, -4.3900e-08,  5.4810e-08,  8.3865e-10,\n",
       "         -1.9421e-07,  4.9690e-08, -1.5148e-07,  6.2731e-08, -1.0120e-07,\n",
       "          2.3235e-08, -7.6916e-08,  2.2195e-07,  2.0219e-07, -4.6712e-08,\n",
       "          1.2108e-08, -5.3027e-08, -8.3254e-08, -1.4881e-07,  6.5468e-08,\n",
       "         -9.2160e-09, -1.9083e-07,  8.1102e-08, -6.7473e-08, -5.9956e-08,\n",
       "         -3.7754e-08, -2.1410e-08,  3.9679e-07, -9.7656e-08, -7.6620e-08,\n",
       "         -2.8265e-08, -4.6514e-08, -3.8908e-08, -9.0371e-08,  1.0389e-07,\n",
       "         -9.9004e-09,  5.1192e-08,  3.1554e-08,  1.3322e-08,  9.5339e-08,\n",
       "         -3.2214e-08,  9.2594e-09, -2.6670e-07, -1.0513e-07,  5.2498e-09,\n",
       "          1.2429e-07, -5.2365e-08, -1.1623e-07, -6.5650e-08, -1.0260e-07,\n",
       "          1.1419e-07, -2.0356e-07, -6.1438e-08, -5.2956e-08, -4.9942e-08,\n",
       "         -1.5696e-08, -1.2778e-07,  5.4449e-08,  1.6486e-08, -2.3149e-07,\n",
       "          1.1418e-07, -2.2268e-08, -1.1629e-07]], grad_fn=<TanhBackward0>), hidden_states=(tensor([[[-0.0040,  0.0341,  0.0052,  ..., -0.0135, -0.0050, -0.0158],\n",
       "         [-0.0738,  0.1526, -0.0361,  ..., -0.1129,  0.0895,  0.0226],\n",
       "         [ 0.0135, -0.1652, -0.0310,  ...,  0.0245, -0.0433,  0.0080],\n",
       "         ...,\n",
       "         [-0.0868, -0.0237,  0.1242,  ..., -0.0409, -0.0539, -0.0572],\n",
       "         [-0.0270,  0.0475, -0.0193,  ..., -0.1622,  0.0744,  0.0075],\n",
       "         [-0.0235,  0.0922, -0.0704,  ..., -0.1180,  0.0551, -0.0483]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.2861, -0.1169,  0.4456,  ...,  0.2834, -0.1101, -0.4562],\n",
       "         [-0.3545,  0.3389,  0.0718,  ...,  0.0164,  0.2093,  0.1230],\n",
       "         [-0.0881, -0.1455, -0.2852,  ...,  0.0192, -0.1755,  0.4035],\n",
       "         ...,\n",
       "         [-0.1898,  0.1294,  0.2501,  ..., -0.4086,  0.0446, -0.3249],\n",
       "         [ 0.1823,  0.1884,  0.0227,  ..., -0.8576,  0.1334, -0.2161],\n",
       "         [ 0.0208,  0.2283, -0.0190,  ..., -0.6523,  0.1116, -0.3260]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[-0.0700,  0.0154,  0.5438,  ...,  0.3682, -0.1259, -0.6339],\n",
       "         [-0.4621,  0.4740,  0.0432,  ...,  0.0977,  0.2557,  0.2291],\n",
       "         [-0.1421, -0.1237, -0.2848,  ...,  0.1872, -0.0530,  0.6094],\n",
       "         ...,\n",
       "         [-0.6285,  0.1509,  0.2331,  ..., -0.4838,  0.1140, -0.2845],\n",
       "         [-0.2259,  0.2858,  0.0831,  ..., -0.9060,  0.0932, -0.1385],\n",
       "         [-0.3174,  0.2394, -0.0426,  ..., -0.7465,  0.1666, -0.1996]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[ 0.1728,  0.1867,  0.6265,  ...,  0.3782, -0.0103, -0.2168],\n",
       "         [-0.1939,  0.6501,  0.0577,  ..., -0.2326,  0.3031,  0.5532],\n",
       "         [ 0.0560, -0.0142, -0.2315,  ..., -0.0945,  0.0828,  0.8958],\n",
       "         ...,\n",
       "         [-0.2453,  0.0129,  0.3111,  ..., -0.7157,  0.1860,  0.1140],\n",
       "         [ 0.3223,  0.0769,  0.2104,  ..., -1.0158,  0.0902,  0.3007],\n",
       "         [ 0.0360,  0.1936, -0.0208,  ..., -0.9804,  0.0939,  0.4077]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[ 0.1386,  0.2821,  0.9127,  ...,  1.1431,  0.0757, -0.1763],\n",
       "         [-0.1573,  0.7282, -0.0682,  ...,  0.2064,  0.1042,  0.3365],\n",
       "         [ 0.0287,  0.1875, -0.1446,  ...,  0.0915,  0.1425,  0.9271],\n",
       "         ...,\n",
       "         [-0.2729,  0.0200,  0.2133,  ..., -0.3442,  0.3150,  0.1489],\n",
       "         [ 0.2058,  0.0945,  0.0908,  ..., -0.7044,  0.2861,  0.3771],\n",
       "         [ 0.0613,  0.3334, -0.0544,  ..., -0.7578,  0.2424,  0.2795]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[ 0.3185,  0.2141,  1.0851,  ...,  1.3507, -0.2420, -0.5926],\n",
       "         [-0.1954,  0.6080, -0.1151,  ...,  0.0507,  0.1649,  0.0257],\n",
       "         [ 0.0840,  0.0628, -0.0349,  ..., -0.0144,  0.0911,  0.7685],\n",
       "         ...,\n",
       "         [-0.4189, -0.0697, -0.0373,  ..., -0.3331,  0.0737, -0.0193],\n",
       "         [ 0.1271,  0.0571, -0.1441,  ..., -0.7692,  0.1163,  0.3356],\n",
       "         [-0.0616,  0.3170, -0.2809,  ..., -0.7773,  0.1734,  0.0389]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[ 0.7795,  0.2089,  1.9493,  ...,  1.9670, -0.6777, -1.2389],\n",
       "         [ 0.1383,  0.3105, -0.2489,  ...,  0.0179,  0.1848,  0.0397],\n",
       "         [ 0.7746, -0.3111, -0.1438,  ..., -0.0322,  0.2770,  0.7698],\n",
       "         ...,\n",
       "         [-0.0408, -0.2871,  0.0378,  ..., -0.1935,  0.2086, -0.0591],\n",
       "         [ 0.4474, -0.1980, -0.1075,  ..., -0.6402,  0.2035,  0.4563],\n",
       "         [ 0.3163,  0.0220, -0.2640,  ..., -0.6902,  0.3198,  0.1212]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[ 0.7161,  0.3280,  2.6135,  ...,  2.0307, -0.9254, -1.1719],\n",
       "         [ 0.1599,  0.5644, -0.4003,  ..., -0.0190,  0.0221,  0.0158],\n",
       "         [ 0.8383, -0.1928, -0.1783,  ..., -0.1126,  0.1903,  0.5588],\n",
       "         ...,\n",
       "         [-0.1087, -0.2668,  0.0814,  ..., -0.2896,  0.1398, -0.0785],\n",
       "         [ 0.3173, -0.0876, -0.0299,  ..., -0.7394,  0.0693,  0.3475],\n",
       "         [ 0.2126,  0.0831, -0.2219,  ..., -0.7552,  0.3175,  0.0912]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[ 7.3627e-01, -7.9320e-03,  2.8717e+00,  ...,  1.9349e+00,\n",
       "          -7.7130e-01, -1.5793e+00],\n",
       "         [ 1.5961e-01,  6.1351e-01, -6.0500e-01,  ..., -6.9199e-02,\n",
       "          -4.3709e-02, -1.0095e-01],\n",
       "         [ 7.8694e-01, -3.2115e-01, -3.5489e-01,  ...,  4.2208e-02,\n",
       "           2.3598e-01,  5.3411e-01],\n",
       "         ...,\n",
       "         [-1.2723e-01, -2.9009e-01, -3.0644e-02,  ..., -2.4251e-01,\n",
       "           2.6878e-01, -2.8140e-01],\n",
       "         [ 3.2067e-01, -8.0312e-02, -2.4270e-03,  ..., -6.4875e-01,\n",
       "           2.6000e-01,  1.4401e-01],\n",
       "         [ 1.6483e-01,  2.0384e-01, -2.6548e-01,  ..., -6.5280e-01,\n",
       "           4.1472e-01,  1.0150e-02]]], grad_fn=<AddBackward0>), tensor([[[ 0.3041,  0.4422,  3.7004,  ...,  3.2447, -1.6386, -1.8679],\n",
       "         [ 0.0510,  0.9165, -0.3679,  ...,  0.0971, -0.2320, -0.0909],\n",
       "         [ 0.7103, -0.0153, -0.4295,  ..., -0.0747,  0.0407,  0.5604],\n",
       "         ...,\n",
       "         [-0.1219, -0.1752, -0.1995,  ..., -0.1391,  0.1962,  0.0329],\n",
       "         [ 0.4468,  0.0789, -0.2785,  ..., -0.4676,  0.2620,  0.4182],\n",
       "         [ 0.0742,  0.3541, -0.4247,  ..., -0.5111,  0.3679,  0.3038]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[-1.0321, -0.3998,  4.9369,  ...,  4.2141, -2.5376, -1.9819],\n",
       "         [ 0.4233,  1.0640, -0.3867,  ..., -0.1931, -0.1638, -0.2252],\n",
       "         [ 1.2220, -0.1570, -0.8026,  ..., -0.2198, -0.0325,  0.2419],\n",
       "         ...,\n",
       "         [ 0.1032, -0.1397, -0.4966,  ..., -0.2014,  0.1739,  0.3730],\n",
       "         [ 0.6778,  0.0216, -0.4859,  ..., -0.5800,  0.2566,  0.6346],\n",
       "         [ 0.3172,  0.4123, -0.6248,  ..., -0.5179,  0.2887,  0.5340]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[-2.7924, -2.5310,  4.0917,  ...,  3.5543, -2.7511, -1.6115],\n",
       "         [ 0.5473,  1.1698, -0.1568,  ..., -0.0837, -0.4157, -0.2931],\n",
       "         [ 1.0387, -0.0586, -0.9030,  ..., -0.2809, -0.1345,  0.0307],\n",
       "         ...,\n",
       "         [ 0.3173, -0.1842, -0.2483,  ...,  0.0589, -0.1224,  0.4124],\n",
       "         [ 0.7500, -0.0521, -0.4057,  ..., -0.2384, -0.1382,  0.4361],\n",
       "         [ 0.4659,  0.2171, -0.4559,  ..., -0.2394, -0.0672,  0.3731]]],\n",
       "       grad_fn=<AddBackward0>), tensor([[[-3.3794, -3.8979,  4.1226,  ...,  4.0289, -3.3232, -1.2213],\n",
       "         [ 0.2987,  0.6878, -0.3482,  ...,  0.0853, -0.7469, -0.2920],\n",
       "         [ 0.7838, -0.6401, -1.0515,  ...,  0.0114, -0.7368,  0.0206],\n",
       "         ...,\n",
       "         [-0.0762, -0.9270, -0.0383,  ...,  0.5695, -0.6192,  0.7516],\n",
       "         [ 0.2827, -0.8014, -0.1499,  ...,  0.5087, -0.8022,  0.8384],\n",
       "         [-0.0091, -0.6900, -0.2262,  ...,  0.5412, -0.7611,  0.7734]]],\n",
       "       grad_fn=<AddBackward0>)), attentions=None), multimodal_embeddings=None, multimodal_output=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(input_ids=inputs['input_ids'])\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
