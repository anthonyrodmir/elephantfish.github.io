@article{openflamingo,
  title={OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and Jitsev, Jenia and Kornblith, Simon and Koh, Pang Wei and Ilharco, Gabriel and Wortsman, Mitchell and Schmidt, Ludwig},
  journal={ArXiv},
  year={2023},
  url={https://arxiv.org/pdf/2308.01390.pdf}
}
@article{flamingo,
  title={Flamingo: a Visual Language Model for Few-Shot Learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob and Borgeaud, Sebastian and Brock, Andrew and Nematzadeh, Aida and Sharifzadeh, Sahand and Binkowski, Mikolaj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Karen},
  journal={ArXiv},
  year={2022},
  url={https://arxiv.org/pdf/2204.14198.pdf}
}
@article{clip,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Radford, Alec Radford and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  journal={ArXiv},
  year={2021},
  url={https://arxiv.org/pdf/2103.00020.pdf}
}
@article{vision-gnn,
  title={Vision GNN: An Image is Worth Graph of Nodes},
  author={Kai Han, Yunhe Wang, Jianyuan Guo, Yehui Tang, Enhua Wu},
  journal={ArXiv},
  year={2022},
  url={https://arxiv.org/pdf/2206.00272.pdf}
}
@article{ai2d,
  title={A Diagram is Worth a Dozen Images},
  author={Kembhavi, Aniruddha and Salvato, Mike and Kolve, Eric and Seo, Minjoon and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={ArXiv},
  year={2016},
  url={https://arxiv.org/pdf/1603.07396.pdf}
}

@article{flowchart,
title = {FlowchartQA The First Large-Scale Benchmark for Reasoning over Flowcharts},
author={Tannert, Simon and Feighelstein, Marcelo and Bogojeska, Jasmina and Shtok4, Joseph and Arbelle, Assaf and Staar, Peter Staar and Schumann, Anika and Kuhn, Jonas and Karlinsky, Leonid},
journal={Document Intelligence},
  year={DI-2022},
  url={https://document-intelligence.github.io/DI-2022/files/di-2022_final_11.pdf}
  }

@article{bizgraphqa,
author = {Babkin, Petr and Watson, William and Ma, Zhiqiang and Cecchi, Lucas and Raman, Natraj and Nourbakhsh, Armineh and Shah, Sameena},
title = {BizGraphQA: A Dataset for Image-Based Inference over Graph-Structured Diagrams from Business Domains},
year = {2023},
url = {https://doi.org/10.1145/3539618.3591875},
doi = {10.1145/3539618.3591875},
journal = {SIGIR}
}

@article{bizgraphqa,
author = {Babkin, Petr and Watson, William and Ma, Zhiqiang and Cecchi, Lucas and Raman, Natraj and Nourbakhsh, Armineh and Shah, Sameena},
title = {BizGraphQA: A Dataset for Image-Based Inference over Graph-Structured Diagrams from Business Domains},
year = {2023},
url = {https://doi.org/10.1145/3539618.3591875},
doi = {10.1145/3539618.3591875},
journal = {SIGIR}
}

@misc{sam,
title={Segment Anything}, 
author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander and Lo, Wan-Yen and Doll√°r, Piotr and Girshick, Ross},
year={2023},
doi={arXiv:2304.02643},
journal={arXiv},
}
