
@article{Chen2023speculativesampling,
  title  = {Accelerating Large Language Model Decoding with Speculative Sampling},
  author = {Chen et al.},
  year   = {2023}
}

@article{Leviathan2023speculativedecoding,
  title  = {Fast Inference from Transformers via Speculative Decoding},
  author = {Leviathan et al.},
  year   = {2023}
}

@article{Cai2023medusa,
  title  = {Medusa: Simple framework for accelerating LLM generation with multiple decoding heads},
  author = {Cai et al.},
  year   = {2023}
}