@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{dota2,
  author    = {Christopher Berner and
               Greg Brockman and
               Brooke Chan and
               Vicki Cheung and
               Przemyslaw Debiak and
               Christy Dennison and
               David Farhi and
               Quirin Fischer and
               Shariq Hashme and
               Christopher Hesse and
               Rafal J{\'{o}}zefowicz and
               Scott Gray and
               Catherine Olsson and
               Jakub Pachocki and
               Michael Petrov and
               Henrique Pond{\'{e}} de Oliveira Pinto and
               Jonathan Raiman and
               Tim Salimans and
               Jeremy Schlatter and
               Jonas Schneider and
               Szymon Sidor and
               Ilya Sutskever and
               Jie Tang and
               Filip Wolski and
               Susan Zhang},
  title     = {Dota 2 with Large Scale Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1912.06680},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.06680},
  eprinttype = {arXiv},
  eprint    = {1912.06680},
  timestamp = {Wed, 03 Jun 2020 10:56:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-06680.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{caron2021emerging,
      title={Emerging Properties in Self-Supervised Vision Transformers}, 
      author={Mathilde Caron and Hugo Touvron and Ishan Misra and Hervé Jégou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
      year={2021},
      eprint={2104.14294},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{chen2021decision,
      title={Decision Transformer: Reinforcement Learning via Sequence Modeling}, 
      author={Lili Chen and Kevin Lu and Aravind Rajeswaran and Kimin Lee and Aditya Grover and Michael Laskin and Pieter Abbeel and Aravind Srinivas and Igor Mordatch},
      year={2021},
      eprint={2106.01345},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{he2015deep,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@article{
noam,
author = {Noam Brown  and Tuomas Sandholm },
title = {Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
journal = {Science},
volume = {359},
number = {6374},
pages = {418-424},
year = {2018},
doi = {10.1126/science.aao1733},
URL = {https://www.science.org/doi/abs/10.1126/science.aao1733},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aao1733},
abstract = {Pitting artificial intelligence (AI) against top human players demonstrates just how far AI has come. Brown and Sandholm built a poker-playing AI called Libratus that decisively beat four leading human professionals in the two-player variant of poker called heads-up no-limit Texas hold'em (HUNL). Over nearly 3 weeks, Libratus played 120,000 hands of HUNL against the human professionals, using a three-pronged approach that included precomputing an overall strategy, adapting the strategy to actual gameplay, and learning from its opponent. Science, this issue p. 418 An artificial intelligence program called Libratus played 120,000 hands of a two-player variant of poker and beat four leading human professionals. No-limit Texas hold’em is the most popular form of poker. Despite artificial intelligence (AI) successes in perfect-information games, the private information and massive game tree have made no-limit poker difficult to tackle. We present Libratus, an AI that, in a 120,000-hand competition, defeated four top human specialist professionals in heads-up no-limit Texas hold’em, the leading benchmark and long-standing challenge problem in imperfect-information game solving. Our game-theoretic approach features application-independent techniques: an algorithm for computing a blueprint for the overall strategy, an algorithm that fleshes out the details of the strategy for subgames that are reached during play, and a self-improver algorithm that fixes potential weaknesses that opponents have identified in the blueprint strategy.}}



@misc{alphazero,
      title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm}, 
      author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
      year={2017},
      eprint={1712.01815},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@article{star,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Oriol Vinyals and Igor Babuschkin and Wojciech M. Czarnecki and Micha{\"e}l Mathieu and Andrew Dudzik and Junyoung Chung and David H. Choi and Richard Powell and Timo Ewalds and Petko Georgiev and Junhyuk Oh and Dan Horgan and Manuel Kroiss and Ivo Danihelka and Aja Huang and L. Sifre and Trevor Cai and John P. Agapiou and Max Jaderberg and Alexander Sasha Vezhnevets and R{\'e}mi Leblond and Tobias Pohlen and Valentin Dalibard and David Budden and Yury Sulsky and James Molloy and Tom Le Paine and Caglar Gulcehre and Ziyun Wang and Tobias Pfaff and Yuhuai Wu and Roman Ring and Dani Yogatama and Dario W{\"u}nsch and Katrina McKinney and Oliver Smith and Tom Schaul and Timothy P. Lillicrap and Koray Kavukcuoglu and Demis Hassabis and Chris Apps and David Silver},
  journal={Nature},
  year={2019},
  volume={575},
  pages={350 - 354},
  url={https://api.semanticscholar.org/CorpusID:204972004}
}
@article{muzero,
  author       = {Julian Schrittwieser and
                  Ioannis Antonoglou and
                  Thomas Hubert and
                  Karen Simonyan and
                  Laurent Sifre and
                  Simon Schmitt and
                  Arthur Guez and
                  Edward Lockhart and
                  Demis Hassabis and
                  Thore Graepel and
                  Timothy P. Lillicrap and
                  David Silver},
  title        = {Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model},
  journal      = {CoRR},
  volume       = {abs/1911.08265},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.08265},
  eprinttype    = {arXiv},
  eprint       = {1911.08265},
  timestamp    = {Mon, 02 Dec 2019 17:48:37 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-08265.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}