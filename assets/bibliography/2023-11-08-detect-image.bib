@misc{zhang2023watermarks,
      title={Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models}, 
      author={Hanlin Zhang and Benjamin L. Edelman and Danilo Francati and Daniele Venturi and Giuseppe Ateniese and Boaz Barak},
      year={2023},
      eprint={2311.04378},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{mope,
      title={MoPe: Model Perturbation-based Privacy Attacks on Language Models}, 
      author={Marvin Li and Jason Wang and Jeffrey Wang and Seth Neel},
      year={2023},
      eprint={2310.14369},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{mitchell2023detectgpt, author = {Mitchell, Eric and Lee, Yoonho and Khazatsky, Alexander and Manning, Christopher D. and Finn, Chelsea}, title = {DetectGPT: Zero-Shot Machine-Generated Text Detection Using Probability Curvature}, year = {2023}, publisher = {JMLR.org}, abstract = {The increasing fluency and widespread usage of large language models (LLMs) highlight the desirability of corresponding tools aiding detection of LLM-generated text. In this paper, we identify a property of the structure of an LLM's probability function that is useful for such detection. Specifically, we demonstrate that text sampled from an LLM tends to occupy negative curvature regions of the model's log probability function. Leveraging this observation, we then define a new curvature-based criterion for judging if a passage is generated from a given LLM. This approach, which we call DetectGPT, does not require training a separate classifier, collecting a dataset of real or generated passages, or explicitly watermarking generated text. It uses only log probabilities computed by the model of interest and random perturbations of the passage from another generic pre-trained language model (e.g., T5). We find DetectGPT is more discriminative than existing zero-shot methods for model sample detection, notably improving detection of fake news articles generated by 20B parameter GPT-NeoX from 0.81 AUROC for the strongest zero-shot baseline to 0.95 AUROC for Detect-GPT. See ericmitchell.ai/detectgpt for code, data, and other project information.}, booktitle = {Proceedings of the 40th International Conference on Machine Learning}, articleno = {1038}, numpages = {13}, location = {Honolulu, Hawaii, USA}, series = {ICML'23} }
@article{wang2022diffusiondb,
  title={DiffusionDB: A Large-Scale Prompt Gallery Dataset for Text-to-Image Generative Models},
  author={Wang, Zijie J and Montoya, Evan and Munechika, David and Yang, Haoyang and Hoover, Benjamin and Chau, Duen Horng},
  journal={arXiv preprint arXiv:2210.14896},
  year={2022}
}
@inproceedings{ilyas2019adversarial,
	author = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Adversarial Examples Are Not Bugs, They Are Features},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf},
	volume = {32},
	year = {2019},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper_files/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf}}

@article{carlinifpr,
  author       = {Nicholas Carlini and
                  Steve Chien and
                  Milad Nasr and
                  Shuang Song and
                  Andreas Terzis and
                  Florian Tram{\`{e}}r},
  title        = {Membership Inference Attacks From First Principles},
  journal      = {CoRR},
  volume       = {abs/2112.03570},
  year         = {2021},
  url          = {https://arxiv.org/abs/2112.03570},
  eprinttype    = {arXiv},
  eprint       = {2112.03570},
  timestamp    = {Mon, 13 Dec 2021 17:51:48 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2112-03570.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchaboutnfdi

@article{sha2022fake,
  title={DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Diffusion Models},
  author={Sha, Zeyang and Li, Zheng and Yu, Ning and Zhang, Yang},
  journal={arXiv preprint arXiv:2210.06998},
  year={2022}
}
@inproceedings{lin2014microsoft,
  title={Microsoft COCO: Common Objects in Context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}
@inproceedings{corvi2023detection,
  title={On the Detection of Synthetic Images Generated by Diffusion Models},
  author={Corvi, Riccardo and Cozzolino, Davide and Zingarini, Giada and Poggi, Giovanni and Nagano, Koki and Verdoliva, Luisa},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}
@inproceedings{rombach2022high,
  title={High-Resolution Image Synthesis with Latent Diffusion Models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}
@article{ho2020denoising,
  title={Denoising Diffusion Probabilistic Models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{batzolis2022your,
  title={Your Diffusion Model Secretly Knows the Dimension of the Data Manifold},
  author={Batzolis, Georgios and Stanczuk, Jan and Sch{\"o}nlieb, Carola-Bibiane},
  journal={arXiv preprint arXiv:2212.12611},
  year={2022}
}

@inproceedings{sohl2015deep,
  title={Deep Unsupervised Learning Using Nonequilibrium Thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}