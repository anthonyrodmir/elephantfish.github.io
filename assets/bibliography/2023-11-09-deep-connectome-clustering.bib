@article{yan2017network,
  title={Network control principles predict neuron function in the Caenorhabditis elegans connectome},
  author={Yan, Gang and V{\'e}rtes, Petra E and Towlson, Emma K and Chew, Yee Lian and Walker, Denise S and Schafer, William R and Barab{\'a}si, Albert-L{\'a}szl{\'o}},
  journal={Nature},
  volume={550},
  number={7677},
  pages={519--523},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@article{winding2023connectome,
  title={The connectome of an insect brain},
  author={Winding, Michael and Pedigo, Benjamin D and Barnes, Christopher L and Patsolic, Heather G and Park, Youngser and Kazimiers, Tom and Fushiki, Akira and Andrade, Ingrid V and Khandelwal, Avinash and Valdes-Aleman, Javier and others},
  journal={Science},
  volume={379},
  number={6636},
  pages={eadd9330},
  year={2023},
  publisher={American Association for the Advancement of Science}
}

@article{jumper2021highly,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{zhu2023unsupervised,
  title={Unsupervised Graph Representation Learning with Cluster-aware Self-training and Refining},
  author={Zhu, Yanqiao and Xu, Yichen and Yu, Feng and Liu, Qiang and Wu, Shu},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={14},
  number={5},
  pages={1--21},
  year={2023},
  publisher={ACM New York, NY}
}

@article{kipf2016variational,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  year={2016}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@online{januszewski2023google,
    title={Google Research embarks on effort to map a mouse brain},
    author={Michał Januszewski},
    url = {https://blog.research.google/2023/09/google-research-embarks-on-effort-to.html},
    year={2023},
    publisher={Google Research}
}

@article{gross_genealogy_2002,
	title = {Genealogy of the "grandmother cell"},
	volume = {8},
	issn = {1073-8584},
	doi = {10.1177/107385802237175},
	abstract = {A "grandmother cell" is a hypothetical neuron that responds only to a highly complex, specific, and meaningful stimulus, such as the image of one's grandmother. The term originated in a parable Jerry Lettvin told in 1967. A similar concept had been systematically developed a few years earlier by Jerzy Konorski who called such cells "gnostic" units. This essay discusses the origin, influence, and current status of these terms and of the alternative view that complex stimuli are represented by the pattern of firing across ensembles of neurons.},
	language = {eng},
	number = {5},
	journal = {The Neuroscientist: A Review Journal Bringing Neurobiology, Neurology and Psychiatry},
	author = {Gross, Charles G.},
	month = oct,
	year = {2002},
	pmid = {12374433},
	keywords = {Animals, History, 20th Century, Humans, Models, Neurological, Neurons, Neurophysiology, Perception, Poland, Temporal Lobe},
	pages = {512--518},
}

@incollection{ricci_hierarchical_2020,
	address = {New York, NY},
	title = {Hierarchical Models of the Visual System},
	isbn = {978-1-4614-7320-6},
	url = {https://doi.org/10.1007/978-1-4614-7320-6_345-2},
	language = {en},
	urldate = {2023-12-11},
	booktitle = {Encyclopedia of {Computational} {Neuroscience}},
	publisher = {Springer},
	author = {Ricci, Matthew and Serre, Thomas},
	editor = {Jaeger, Dieter and Jung, Ranu},
	year = {2020},
	doi = {10.1007/978-1-4614-7320-6_345-2},
	pages = {1--14},
}

@article{xu_cortisol_2019,
	title = {Cortisol Excess-Mediated Mitochondrial Damage Induced Hippocampal Neuronal Apoptosis in Mice Following Cold Exposure},
	volume = {8},
	issn = {2073-4409},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6627841/},
	doi = {10.3390/cells8060612},
	abstract = {Cold stress can induce neuronal apoptosis in the hippocampus, but the internal mechanism involving neuronal loss induced by cold stress is not clear. In vivo, male and female C57BL/6 mice were exposed to 4 °C, 3 h per day for 1 week. In vitro, HT22 cells were treated with different concentrations of cortisol (CORT) for 3 h. In vivo, CORT levels in the hippocampus were measured using ELISA, western blotting, and immunohistochemistry to assess the neuronal population and oxidation of the hippocampus. In vitro, western blotting, immunofluorescence, flow cytometry, transmission electron microscopy, and other methods were used to characterize the mechanism of mitochondrial damage induced by CORT. The phenomena of excessive CORT-mediated oxidation stress and neuronal apoptosis were shown in mouse hippocampus tissue following cold exposure, involving mitochondrial oxidative stress and endogenous apoptotic pathway activation. These processes were mediated by acetylation of lysine 9 of histone 3, resulting in upregulation involving Adenosine 5‘-monophosphate (AMP)-activated protein kinase (APMK) phosphorylation and translocation of Nrf2 to the nucleus. In addition, oxidation in male mice was more severe. These findings provide a new understanding of the underlying mechanisms of the cold stress response and explain the apoptosis process induced by CORT, which may influence the selection of animal models in future stress-related studies.},
	number = {6},
	urldate = {2023-12-11},
	journal = {Cells},
	author = {Xu, Bin and Lang, Li-min and Li, Shi-Ze and Guo, Jing-Ru and Wang, Jian-Fa and Wang, Di and Zhang, Li-Ping and Yang, Huan-Min and Lian, Shuai},
	month = jun,
	year = {2019},
	pmid = {31216749},
	pmcid = {PMC6627841},
	pages = {612},
	file = {PubMed Central Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\3HXJZQV3\\Xu et al. - 2019 - Cortisol Excess-Mediated Mitochondrial Damage Indu.pdf:application/pdf},
}

@article{coifman_geometric_2005,
	title = {Geometric diffusions as a tool for harmonic analysis and structure definition of data: Diffusion maps},
	volume = {102},
	issn = {0027-8424},
	shorttitle = {Geometric diffusions as a tool for harmonic analysis and structure definition of data},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1140422/},
	doi = {10.1073/pnas.0500334102},
	number = {21},
	urldate = {2023-12-12},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Coifman, R. R. and Lafon, S. and Lee, A. B. and Maggioni, M. and Nadler, B. and Warner, F. and Zucker, S. W.},
	month = may,
	year = {2005},
	pmid = {15899970},
	pmcid = {PMC1140422},
	pages = {7426--7431},
	file = {PubMed Central Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\FB7369L7\\Coifman et al. - 2005 - Geometric diffusions as a tool for harmonic analys.pdf:application/pdf},
}

@article{sporns_human_2005,
	title = {The Human Connectome: A Structural Description of the Human Brain},
	volume = {1},
	issn = {1553-734X},
	shorttitle = {The {Human} {Connectome}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1239902/},
	doi = {10.1371/journal.pcbi.0010042},
	abstract = {The connection matrix of the human brain (the human “connectome”) represents an indispensable foundation for basic and applied neurobiological research. However, the network of anatomical connections linking the neuronal elements of the human brain is still largely unknown. While some databases or collations of large-scale anatomical connection patterns exist for other mammalian species, there is currently no connection matrix of the human brain, nor is there a coordinated research effort to collect, archive, and disseminate this important information. We propose a research strategy to achieve this goal, and discuss its potential impact.},
	number = {4},
	urldate = {2023-12-12},
	journal = {PLoS Computational Biology},
	author = {Sporns, Olaf and Tononi, Giulio and Kötter, Rolf},
	month = sep,
	year = {2005},
	pmid = {16201007},
	pmcid = {PMC1239902},
	pages = {e42},
	file = {PubMed Central Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\BYL3FNMR\\Sporns et al. - 2005 - The Human Connectome A Structural Description of .pdf:application/pdf},
}

@article{lai_identification_2000,
	title = {Identification of Novel Human Genes Evolutionarily Conserved in Caenorhabditis elegans by Comparative Proteomics},
	volume = {10},
	issn = {1088-9051},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC310876/},
	abstract = {Modern biomedical research greatly benefits from large-scale genome-sequencing projects ranging from studies of viruses, bacteria, and yeast to multicellular organisms, like Caenorhabditis elegans. Comparative genomic studies offer a vast array of prospects for identification and functional annotation of human ortholog genes. We presented a novel comparative proteomic approach for assembling human gene contigs and assisting gene discovery. The C. elegans proteome was used as an alignment template to assist in novel human gene identification from human EST nucleotide databases. Among the available 18,452 C. elegans protein sequences, our results indicate that at least 83\% (15,344 sequences) of C. elegans proteome has human homologous genes, with 7,954 records of C. elegans proteins matching known human gene transcripts. Only 11\% or less of C. elegans proteome contains nematode-specific genes. We found that the remaining 7,390 sequences might lead to discoveries of novel human genes, and over 150 putative full-length human gene transcripts were assembled upon further database analyses., [The sequence data described in this paper have been submitted to the GenBank data library under accession nos. AF132936–AF132973, AF151799–AF151909, and AF152097.]},
	number = {5},
	urldate = {2023-12-12},
	journal = {Genome Research},
	author = {Lai, Chun-Hung and Chou, Chang-Yuan and Ch'ang, Lan-Yang and Liu, Chung-Shyan and Lin, Wen-chang},
	month = may,
	year = {2000},
	pmid = {10810093},
	pmcid = {PMC310876},
	pages = {703--713},
	file = {PubMed Central Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\23AMD565\\Lai et al. - 2000 - Identification of Novel Human Genes Evolutionarily.pdf:application/pdf},
}

@misc{noauthor_facts_nodate,
	title = {Facts},
	url = {https://www.mpg.de/10973625/why-do-scientists-investigate-fruit-flies},
	abstract = {The high genetic similarity with mammals and its high fidelity make Drosophila to a popular model organism for scientists},
	language = {en},
	urldate = {2023-12-12},
	file = {Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\CQ7HSWWH\\why-do-scientists-investigate-fruit-flies.html:text/html},
}

@article{kanwisher_fusiform_2006,
	title = {The fusiform face area: a cortical region specialized for the perception of faces},
	volume = {361},
	issn = {0962-8436},
	shorttitle = {The fusiform face area},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1857737/},
	doi = {10.1098/rstb.2006.1934},
	abstract = {Faces are among the most important visual stimuli we perceive, informing us not only about a person's identity, but also about their mood, sex, age and direction of gaze. The ability to extract this information within a fraction of a second of viewing a face is important for normal social interactions and has probably played a critical role in the survival of our primate ancestors. Considerable evidence from behavioural, neuropsychological and neurophysiological investigations supports the hypothesis that humans have specialized cognitive and neural mechanisms dedicated to the perception of faces (the face-specificity hypothesis). Here, we review the literature on a region of the human brain that appears to play a key role in face perception, known as the fusiform face area (FFA).,  outlines the theoretical background for much of this work. The face-specificity hypothesis falls squarely on one side of a longstanding debate in the fields of cognitive science and cognitive neuroscience concerning the extent to which the mind/brain is composed of: (i) special-purpose (‘domain-specific’) mechanisms, each dedicated to processing a specific kind of information (e.g. faces, according to the face-specificity hypothesis), versus (ii) general-purpose (‘domain-general’) mechanisms, each capable of operating on any kind of information. Face perception has long served both as one of the prime candidates of a domain-specific process and as a key target for attack by proponents of domain-general theories of brain and mind.  briefly reviews the prior literature on face perception from behaviour and neurophysiology. This work supports the face-specificity hypothesis and argues against its domain-general alternatives (the individuation hypothesis, the expertise hypothesis and others).,  outlines the more recent evidence on this debate from brain imaging, focusing particularly on the FFA. We review the evidence that the FFA is selectively engaged in face perception, by addressing (and rebutting) five of the most widely discussed alternatives to this hypothesis. In , we consider recent findings that are beginning to provide clues into the computations conducted in the FFA and the nature of the representations the FFA extracts from faces. We argue that the FFA is engaged both in detecting faces and in extracting the necessary perceptual information to recognize them, and that the properties of the FFA mirror previously identified behavioural signatures of face-specific processing (e.g. the face-inversion effect).,  asks how the computations and representations in the FFA differ from those occurring in other nearby regions of cortex that respond strongly to faces and objects. The evidence indicates clear functional dissociations between these regions, demonstrating that the FFA shows not only functional specificity but also area specificity. We end by speculating in  on some of the broader questions raised by current research on the FFA, including the developmental origins of this region and the question of whether faces are unique versus whether similarly specialized mechanisms also exist for other domains of high-level perception and cognition.},
	number = {1476},
	urldate = {2023-12-12},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Kanwisher, Nancy and Yovel, Galit},
	month = dec,
	year = {2006},
	pmid = {17118927},
	pmcid = {PMC1857737},
	pages = {2109--2128},
	file = {PubMed Central Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\QEZ2AHFH\\Kanwisher and Yovel - 2006 - The fusiform face area a cortical region speciali.pdf:application/pdf},
}

@article{spelke_core_2007,
	title = {Core knowledge},
	volume = {10},
	issn = {1363-755X, 1467-7687},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00569.x},
	doi = {10.1111/j.1467-7687.2007.00569.x},
	abstract = {Human cognition is founded, in part, on four systems for representing objects, actions, number, and space. It may be based, as well, on a ﬁfth system for representing social partners. Each system has deep roots in human phylogeny and ontogeny, and it guides and shapes the mental lives of adults. Converging research on human infants, non-human primates, children and adults in diverse cultures can aid both understanding of these systems and attempts to overcome their limits.},
	language = {en},
	number = {1},
	urldate = {2023-12-12},
	journal = {Developmental Science},
	author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
	month = jan,
	year = {2007},
	pages = {89--96},
	file = {Spelke and Kinzler - 2007 - Core knowledge.pdf:C\:\\Users\\eliu\\Zotero\\storage\\H2TPHI7R\\Spelke and Kinzler - 2007 - Core knowledge.pdf:application/pdf},
}

@article{otsuka_face_2014,
	title = {Face recognition in infants: A review of behavioral and near-infrared spectroscopic studies},
	volume = {56},
	copyright = {© 2013 Japanese Psychological Association},
	issn = {1468-5884},
	shorttitle = {Face recognition in infants},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jpr.12024},
	doi = {10.1111/jpr.12024},
	abstract = {Recent developmental studies investigating face recognition ability in infants’ have provided evidence not only that infants show selective attention to faces, but also that they can discriminate between faces from birth, and that biases in face processing such as the face inversion and other race effects exist even in infancy. Studies measuring the hemodynamic responses to facial images in the infants’ brain using near-infrared spectroscopy (NIRS) have also reported differential cortical activity in response to face and nonface images in infants. This paper will review recent findings on infants face recognition provided by both behavioral studies and neuroimaging studies using NIRS. These converging lines of evidence point to the early onset of face recognition ability in infancy.},
	language = {en},
	number = {1},
	urldate = {2023-12-12},
	journal = {Japanese Psychological Research},
	author = {Otsuka, Yumiko},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jpr.12024},
	keywords = {face recognition, fNIRS, infants, preference},
	pages = {76--90},
	file = {Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\ZXLV3D2S\\Otsuka - 2014 - Face recognition in infants A review of behaviora.pdf:application/pdf;Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\9S9ZPW57\\jpr.html:text/html},
}

@article{gochin_neural_1994,
	title = {Neural ensemble coding in inferior temporal cortex},
	volume = {71},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/abs/10.1152/jn.1994.71.6.2325},
	doi = {10.1152/jn.1994.71.6.2325},
	abstract = {1. Isolated, single-neuron extracellular potentials were recorded sequentially in area TE of the inferior temporal cortex (IT) of two macaque monkeys (n = 58 and n = 41 neurons). Data were obtained while the animals were performing a paired-associate task. The task utilized five stimuli and eight stimulus pairings (4 correct and 4 incorrect). Data were evaluated as average spike rate during experimental epochs of 100 or 400 ms. Single-unit and population characteristics were measured using a form of linear discriminant analysis and information theoretic measures. To evaluate the significance of covariance on population code measures, additional data consisting of simultaneous recordings from {\textless} or = 8 isolated neurons (n = 37) were obtained from a third macaque monkey that was passively viewing visual stimuli. 2. On average, 43\% of IT neurons were activated by any of the stimuli used (60\% if those inhibited also are included). Yet the neurons were rather unique in the relative magnitude of their responses to each stimulus in the test set. These results suggest that information may be represented in IT by the pattern of activity across neurons and that the representation is not sparsely coded. It is further suggested that the representation scheme may have similarities to DNA or computer codes wherein a coding element is not a local parametric descriptor. This is a departure from the V1 representation, which appears to be both local and parametric. It is also different from theories of IT representation that suggest a constructive basis set or “alphabet”. From this view, determination of stimulus discrimination capacity in IT should be evaluated by measures of population activity patterns. 3. Evaluation of small groups of simultaneously recorded neurons obtained during a fixation task suggests that little information about visual stimuli is conveyed by covariance of activity in IT when a 100-ms time scale is used as in this study. This finding is consistent with a prior report, by Gochin et al., which used a 1-ms time scale and failed to find neural activity coherence or oscillations dependent on stimuli. 4. Population-stimulus-discrimination capacity measures were influenced by the number of neurons and to some extent the number and type of stimuli. 5. Information conveyed by individual neurons (mutual information) averaged 0.26 bits. The distribution of information values was unimodal and is therefore more consistent with a distributed than a local coding scheme.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {6},
	urldate = {2023-12-12},
	journal = {Journal of Neurophysiology},
	author = {Gochin, P. M. and Colombo, M. and Dorfman, G. A. and Gerstein, G. L. and Gross, C. G.},
	month = jun,
	year = {1994},
	note = {Publisher: American Physiological Society},
	pages = {2325--2337},
	file = {Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\FG3IIB64\\Gochin et al. - 1994 - Neural ensemble coding in inferior temporal cortex.pdf:application/pdf},
}

@article{mcclamrock_marrs_1991,
	title = {Marr's three levels: A re-evaluation},
	volume = {1},
	issn = {1572-8641},
	shorttitle = {Marr's three levels},
	url = {https://doi.org/10.1007/BF00361036},
	doi = {10.1007/BF00361036},
	abstract = {Marr's account of the analysis of complex information-processing tasks as having three levels — the levels of computational theory, representation and algorithm, and hardware implementation — is reconsidered. I argue that the notion of “level” here runs together two distinctive sort of explanatory shifts — that of grain and that of contextual function. I then offer a revision of the account which avoids this problem, and suggest how this might play a role in the practice of theory evaluation.},
	language = {en},
	number = {2},
	urldate = {2023-12-12},
	journal = {Minds and Machines},
	author = {McClamrock, Ron},
	month = may,
	year = {1991},
	keywords = {decomposition, explanation, function, Levels},
	pages = {185--196},
	file = {Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\7GRLEEM8\\McClamrock - 1991 - Marr's three levels A re-evaluation.pdf:application/pdf},
}

@article{winding_connectome_2023,
	title = {The connectome of an insect brain},
	volume = {379},
	url = {https://www.science.org/doi/10.1126/science.add9330},
	doi = {10.1126/science.add9330},
	abstract = {Brains contain networks of interconnected neurons and so knowing the network architecture is essential for understanding brain function. We therefore mapped the synaptic-resolution connectome of an entire insect brain (Drosophila larva) with rich behavior, including learning, value computation, and action selection, comprising 3016 neurons and 548,000 synapses. We characterized neuron types, hubs, feedforward and feedback pathways, as well as cross-hemisphere and brain-nerve cord interactions. We found pervasive multisensory and interhemispheric integration, highly recurrent architecture, abundant feedback from descending neurons, and multiple novel circuit motifs. The brain’s most recurrent circuits comprised the input and output neurons of the learning center. Some structural features, including multilayer shortcuts and nested recurrent loops, resembled state-of-the-art deep learning architectures. The identified brain architecture provides a basis for future experimental and theoretical studies of neural circuits.},
	number = {6636},
	urldate = {2023-12-12},
	journal = {Science},
	author = {Winding, Michael and Pedigo, Benjamin D. and Barnes, Christopher L. and Patsolic, Heather G. and Park, Youngser and Kazimiers, Tom and Fushiki, Akira and Andrade, Ingrid V. and Khandelwal, Avinash and Valdes-Aleman, Javier and Li, Feng and Randel, Nadine and Barsotti, Elizabeth and Correia, Ana and Fetter, Richard D. and Hartenstein, Volker and Priebe, Carey E. and Vogelstein, Joshua T. and Cardona, Albert and Zlatic, Marta},
	month = mar,
	year = {2023},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eadd9330},
	file = {Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\ZI3WMQVN\\Winding et al. - 2023 - The connectome of an insect brain.pdf:application/pdf},
}

@article{shakeshaft_genetic_2015,
	title = {Genetic specificity of face recognition},
	volume = {112},
	issn = {0027-8424},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4611634/},
	doi = {10.1073/pnas.1421881112},
	abstract = {Diverse cognitive abilities have typically been found to intercorrelate highly and to be strongly influenced by genetics. Recent twin studies have suggested that the ability to recognize human faces is an exception: it is similarly highly heritable, but largely uncorrelated with other abilities. However, assessing genetic relationships—the degree to which traits are influenced by the same genes—requires very large samples, which have not previously been available. This study, using data from more than 2,000 twins, shows for the first time, to our knowledge, that the genetic influences on face recognition are almost entirely unique. This finding provides strong support for the view that face recognition is “special” and may ultimately illuminate the nature of cognitive abilities in general., Specific cognitive abilities in diverse domains are typically found to be highly heritable and substantially correlated with general cognitive ability (g), both phenotypically and genetically. Recent twin studies have found the ability to memorize and recognize faces to be an exception, being similarly heritable but phenotypically substantially uncorrelated both with g and with general object recognition. However, the genetic relationships between face recognition and other abilities (the extent to which they share a common genetic etiology) cannot be determined from phenotypic associations. In this, to our knowledge, first study of the genetic associations between face recognition and other domains, 2,000 18- and 19-year-old United Kingdom twins completed tests assessing their face recognition, object recognition, and general cognitive abilities. Results confirmed the substantial heritability of face recognition (61\%), and multivariate genetic analyses found that most of this genetic influence is unique and not shared with other cognitive abilities.},
	number = {41},
	urldate = {2023-12-12},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Shakeshaft, Nicholas G. and Plomin, Robert},
	month = oct,
	year = {2015},
	pmid = {26417086},
	pmcid = {PMC4611634},
	pages = {12887--12892},
	file = {PubMed Central Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\3BWFRQWD\\Shakeshaft and Plomin - 2015 - Genetic specificity of face recognition.pdf:application/pdf},
}

@article{leeds_comparing_2013,
	title = {Comparing visual representations across human fMRI and computational vision},
	volume = {13},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/13.13.25},
	doi = {10.1167/13.13.25},
	abstract = {Feedforward visual object perception recruits a cortical network that is assumed to be hierarchical, progressing from basic visual features to complete object representations. However, the nature of the intermediate features related to this transformation remains poorly understood. Here, we explore how well different computer vision recognition models account for neural object encoding across the human cortical visual pathway as measured using fMRI. These neural data, collected during the viewing of 60 images of real-world objects, were analyzed with a searchlight procedure as in Kriegeskorte, Goebel, and Bandettini (2006): Within each searchlight sphere, the obtained patterns of neural activity for all 60 objects were compared to model responses for each computer recognition algorithm using representational dissimilarity analysis (Kriegeskorte et al., 2008). Although each of the computer vision methods significantly accounted for some of the neural data, among the different models, the scale invariant feature transform (Lowe, 2004), encoding local visual properties gathered from “interest points,” was best able to accurately and consistently account for stimulus representations within the ventral pathway. More generally, when present, significance was observed in regions of the ventral-temporal cortex associated with intermediate-level object perception. Differences in model effectiveness and the neural location of significant matches may be attributable to the fact that each model implements a different featural basis for representing objects (e.g., more holistic or more parts-based). Overall, we conclude that well-known computer vision recognition systems may serve as viable proxies for theories of intermediate visual object representation.},
	number = {13},
	urldate = {2023-12-12},
	journal = {Journal of Vision},
	author = {Leeds, Daniel D. and Seibert, Darren A. and Pyles, John A. and Tarr, Michael J.},
	month = nov,
	year = {2013},
	pages = {25},
	file = {Full Text:C\:\\Users\\eliu\\Zotero\\storage\\PEEDSIUP\\Leeds et al. - 2013 - Comparing visual representations across human fMRI.pdf:application/pdf;Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\8H96G4NZ\\article.html:text/html},
}

@misc{von_luxburg_tutorial_2007,
	title = {A Tutorial on Spectral Clustering},
	url = {http://arxiv.org/abs/0711.0189},
	abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
	urldate = {2023-12-12},
	publisher = {arXiv},
	author = {von Luxburg, Ulrike},
	month = nov,
	year = {2007},
	note = {arXiv:0711.0189 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\UW9MRBMW\\0711.html:text/html;Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\QD2NUMFN\\von Luxburg - 2007 - A Tutorial on Spectral Clustering.pdf:application/pdf},
}

@article{park_spectral_2014,
	title = {Spectral clustering with physical intuition on spring–mass dynamics},
	volume = {351},
	issn = {0016-0032},
	url = {https://www.sciencedirect.com/science/article/pii/S0016003214000532},
	doi = {10.1016/j.jfranklin.2014.02.017},
	abstract = {In this paper, we provide a new insight into clustering with a spring–mass dynamics, and propose a resulting hierarchical clustering algorithm. To realize the spectral graph partitioning as clustering, we model a weighted graph of a data set as a mass–spring dynamical system, where we regard a cluster as an oscillating single entity of a data set with similar properties. And then, we describe how oscillation modes are related with eigenvectors of a graph Laplacian matrix of the data set. In each step of the clustering, we select a group of clusters, which has the biggest number of constituent clusters. This group is divided into sub-clusters by examining an eigenvector minimizing a cost function, which is formed in such a way that subdivided clusters will be balanced with large size. To find k clusters out of non-spherical or complex data, we first transform the data into spherical clusters located on the unit sphere positioned in the (k−1)-dimensional space. In the sequel, we use the previous procedure to these transformed data. The computational experiments demonstrate that the proposed method works quite well on a variety of data sets, although its performance degrades with the degree of overlapping of data sets.},
	number = {6},
	urldate = {2023-12-12},
	journal = {Journal of the Franklin Institute},
	author = {Park, Jinho and Jeon, Moongu and Pedrycz, Witold},
	month = jun,
	year = {2014},
	pages = {3245--3268},
	file = {ScienceDirect Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\Q8P772RM\\S0016003214000532.html:text/html},
}

@article{palamuttam_evaluating_nodate,
	title = {Evaluating Network Embeddings: Node2Vec vs Spectral Clustering vs GCN},
	abstract = {Node classiﬁcation on popular social network datasets in the graph setting arises in various real world networks. Being able to label a particular entity in a graph based on its neighboring graph structure and predicting relationships between entities plays an important role in analyzing social networks and content on the web. With the the resurgence of machine learning, supervised learning problems have been shown to accomplish a number of different tasks from classifying animals to determining the model of cars [7]. These methods have been further extended by the resurgence of Deep Learning to accomplish the same tasks such as classifying images with higher accuracy. However, it is noted by Leskovec et al. [2] that prediction tasks on graphs require careful feature engineering. In this paper we adapt work by Kipf et al [4][5] in order to leverage Graph Convolutional Neural Networks as a means of evaluating spectral embeddings in comparison to embeddings generated by the Node2Vec algorithm.},
	language = {en},
	author = {Palamuttam, Rahul and Mall, Serra},
	file = {Palamuttam and Mall - Evaluating Network Embeddings Node2Vec vs Spectra.pdf:C\:\\Users\\eliu\\Zotero\\storage\\MYU4TY47\\Palamuttam and Mall - Evaluating Network Embeddings Node2Vec vs Spectra.pdf:application/pdf},
}

@misc{grover_node2vec_2016,
	title = {node2vec: Scalable Feature Learning for Networks},
	shorttitle = {node2vec},
	url = {http://arxiv.org/abs/1607.00653},
	abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.},
	urldate = {2023-12-12},
	publisher = {arXiv},
	author = {Grover, Aditya and Leskovec, Jure},
	month = jul,
	year = {2016},
	note = {arXiv:1607.00653 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\JTV22CVH\\1607.html:text/html;Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\9D7IEEW7\\Grover and Leskovec - 2016 - node2vec Scalable Feature Learning for Networks.pdf:application/pdf},
}

@misc{huang_combining_2020,
	title = {Combining Label Propagation and Simple Models Out-performs Graph Neural Networks},
	url = {http://arxiv.org/abs/2010.13993},
	doi = {10.48550/arXiv.2010.13993},
	abstract = {Graph Neural Networks (GNNs) are the predominant technique for learning over graphs. However, there is relatively little understanding of why GNNs are successful in practice and whether they are necessary for good performance. Here, we show that for many standard transductive node classification benchmarks, we can exceed or match the performance of state-of-the-art GNNs by combining shallow models that ignore the graph structure with two simple post-processing steps that exploit correlation in the label structure: (i) an "error correlation" that spreads residual errors in training data to correct errors in test data and (ii) a "prediction correlation" that smooths the predictions on the test data. We call this overall procedure Correct and Smooth (C\&S), and the post-processing steps are implemented via simple modifications to standard label propagation techniques from early graph-based semi-supervised learning methods. Our approach exceeds or nearly matches the performance of state-of-the-art GNNs on a wide variety of benchmarks, with just a small fraction of the parameters and orders of magnitude faster runtime. For instance, we exceed the best known GNN performance on the OGB-Products dataset with 137 times fewer parameters and greater than 100 times less training time. The performance of our methods highlights how directly incorporating label information into the learning algorithm (as was done in traditional techniques) yields easy and substantial performance gains. We can also incorporate our techniques into big GNN models, providing modest gains. Our code for the OGB results is at https://github.com/Chillee/CorrectAndSmooth.},
	urldate = {2023-12-12},
	publisher = {arXiv},
	author = {Huang, Qian and He, Horace and Singh, Abhay and Lim, Ser-Nam and Benson, Austin R.},
	month = nov,
	year = {2020},
	note = {arXiv:2010.13993 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:C\:\\Users\\eliu\\Zotero\\storage\\KAJCKCBD\\Huang et al. - 2020 - Combining Label Propagation and Simple Models Out-.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\MP6Z4TNI\\2010.html:text/html},
}

@misc{lin_use_2021,
	title = {On the Use of Unrealistic Predictions in Hundreds of Papers Evaluating Graph Representations},
	url = {http://arxiv.org/abs/2112.04274},
	doi = {10.48550/arXiv.2112.04274},
	abstract = {Prediction using the ground truth sounds like an oxymoron in machine learning. However, such an unrealistic setting was used in hundreds, if not thousands of papers in the area of finding graph representations. To evaluate the multi-label problem of node classification by using the obtained representations, many works assume in the prediction stage that the number of labels of each test instance is known. In practice such ground truth information is rarely available, but we point out that such an inappropriate setting is now ubiquitous in this research area. We detailedly investigate why the situation occurs. Our analysis indicates that with unrealistic information, the performance is likely over-estimated. To see why suitable predictions were not used, we identify difficulties in applying some multi-label techniques. For the use in future studies, we propose simple and effective settings without using practically unknown information. Finally, we take this chance to conduct a fair and serious comparison of major graph-representation learning methods on multi-label node classification.},
	urldate = {2023-12-12},
	publisher = {arXiv},
	author = {Lin, Li-Chung and Liu, Cheng-Hung and Chen, Chih-Ming and Hsu, Kai-Chin and Wu, I.-Feng and Tsai, Ming-Feng and Lin, Chih-Jen},
	month = dec,
	year = {2021},
	note = {arXiv:2112.04274 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\eliu\\Zotero\\storage\\6AMYQ534\\Lin et al. - 2021 - On the Use of Unrealistic Predictions in Hundreds .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\YXR35ABC\\2112.html:text/html},
}
